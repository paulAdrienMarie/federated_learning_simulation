import json
import argparse

class DatasetCleaner:
    """
    Cleans a dataset that is in a json file
        
    Attributs:
    option -- The dataset of images to handle - can be either train or set
    """
    
    def __init__(self,option):
        """
        Initializes a new instance of the Pipeline class
        
        Arguments:
        option -- The set of images to handle - can be either train or test
        """
        self.option = option,

    def remove_idk_and_none_pattern(self):
        """
        Remove the following patterns of the dataset if present :
            - I don't know
            - i don't know
            - None
            - none
        """
        
        print("Looking for I don't know and none patterns in the dataset")
        # Define the file path
        cache_file_path = f"./cache_{self.option}.json"

        # Open and load the cache JSON file
        with open(cache_file_path) as f:
            cache = json.load(f)
        
        print(f"Initial length of the dataset {len(cache.keys())}")
        # Calculate filtered values
        to_remove = [value for value in cache.values() if value.lower() == "i don't know" or value.lower() == "none"]

        # Print statistics
        print(f"Pattern 'I don't know' and 'none' apperead : {len(to_remove)} times")
        print(f"There are {len(cache) - len(to_remove)} correct outputs")
        
        # Extract values from the cache and filter them
        filtered_dict = {key: value for key, value in cache.items() if value.lower() != "i don't know" and value.lower() != "none"}
        print("Now removing patterns 'I don't know' and 'none' from the dataset")
        # Save the filtered dictionary to a new JSON file
        with open("filtered_dataset_tmp.json", "w") as f:
            json.dump(filtered_dict, f, indent=4)

        
    def check_labels(self):
        """
        Checks if the labels generated by chatGpt-4o do exist in the 
        set of labels in the config.json file
        
        For each unknown labels, check if it indeed does not exist or if
        chatGpt-4o might have only returned a substring of an existing label
        
        In this last case, user is asked to check manually if one of the existing
        label that contains the predicted label could fit to the image
        """
        
        print("Looking for unexisting labels in the dataset")
        
        with open("filtered_dataset_tmp.json") as f:
            data = json.loads(f.read())

        with open("static/config.json") as f:
            true_data = json.loads(f.read())["label2id"]

        true_labels = true_data.keys()
        unknowmn_labels = {}
        labels_to_check = {}

        for (id, label) in data.items():
            found_pattern = False
            possible_labels = None
            if label not in true_labels:
                for true_label in true_labels:
                    if label in true_label:
                        if possible_labels is None :
                            possible_labels = []
                        print(f"Yes label {label} is present in {true_label} for image with id : {id}")
                        possible_labels.append(true_label)    
                        found_pattern = True
                    else:
                        if not found_pattern:
                            unknowmn_labels[id] = label
            labels_to_check[id] = possible_labels

        print(f"There are {len(unknowmn_labels.keys())} unknown labels, saving these ids in skip_ids.json")
        
        with open(f"skip_ids_{self.option}.json","w") as f:
            json.dump(list(unknowmn_labels.keys()),f)
                
        for path,label in labels_to_check.items():
            print(f"Image at path : {path} could fit for one of the following label {label}")
            print("Correct manually in the train.json file")
            
        print("Saving the ids and the possible labels to labels_to_check.json")
        with open(f"labels_to_check_{self.option}.json","w") as f:
            json.dump(labels_to_check,f)
        
        cleaned_dataset = {key: value for key,value in data.items() if value not in unknowmn_labels.values()}
        print(f"Dataset now contains {len(cleaned_dataset.keys())}")
        
        with open(f"./static/{self.option}.json","w") as f:
            json.dump(cleaned_dataset,f)
            
    def __call__(self):
        """
        Runs the whole cleaning process
        """
        
        self.remove_idk_and_none_pattern()
        self.check_labels()

if __name__ == "__main__":
    
    parser = argparse.ArgumentParser(
        prog="Make Dataset"
    )
    
    parser.add_argument("option", type=str, help="Dataset Option")
    
    arg = parser.parse_args()
    
    obj = DatasetCleaner(option=arg.option)
    
    obj()
